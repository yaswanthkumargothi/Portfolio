# -*- coding: utf-8 -*-
"""Copy of crosssectionalconvert.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bAIfLF6s5kKDWPQa1c4fyeF5ohVbReAG
"""

from google.colab import drive
drive.mount('/content/gdrive')

#importing files
import pandas as pd
import numpy as np
from functools import partial
import io
import os
import html
import pickle
import re
from time import time
from tqdm import tqdm, tqdm_notebook
import folium
import seaborn as sns
import matplotlib.pyplot as plt

#loading data
disastersent=pd.read_csv('/content/gdrive/My Drive/inference/disastersenti.csv')

restomerge=pd.read_csv('/content/gdrive/My Drive/inference/Restaurants.csv')

disastersenti=disastersent.drop('Unnamed: 0',axis=1)

disastersenti = disastersenti[disastersenti['categories'].notnull()]

# categories of each row into a list to search for specific categories 
catelist=[]
for i in range(len(disastersenti)):
  catelist.append(disastersenti.iloc[i]['categories'].split(','))

#check for 'Restaurants' in the list of lists
unique_list = 'Restaurants'     
newlist=[]   # traverse for all elements 
for i in range(len(disastersenti)): 
        # check if exists in unique_list or not
  if unique_list in disastersenti.iloc[i]['categories'].split(','):
    newlist.append(1)          
  else:
    newlist.append(0)

disastersenti=disastersenti.reset_index(drop=True)

#appending the restuarant variable to the sentiment dataframe 
Restaurants=pd.DataFrame(newlist,columns=['Restaurants'])
Rest=pd.concat([disastersenti, Restaurants],axis=1)

#extracting only Restaurants from the sentiment dataframe
mask= (Rest['Restaurants']==1)
RestaurantLV=Rest.loc[mask]

# aggregating data cross sectional wise

# 14days before the incident
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-09-16 00:00:00')
daysbef14=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()

#on the 14th day before the incident
mask = (RestaurantLV['date'] > '2017-09-15 00:00:00')&(RestaurantLV['date'] <= '2017-09-16 00:00:00')
ondaybef14=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
# 7 days before the incident
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-09-22 00:00:00')
daysbef7=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 7th day before the incident
mask = (RestaurantLV['date'] > '2017-09-21 00:00:00')&(RestaurantLV['date'] <= '2017-09-22 00:00:00')
ondaybef7=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
# 5 days before the incident
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-09-24 00:00:00')
days5bef=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 5th day before the incident
mask = (RestaurantLV['date'] > '2017-09-23 00:00:00')&(RestaurantLV['date'] <= '2017-09-24 00:00:00')
onday5bef=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
# 3 days before the incident
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-09-27 00:00:00')
days3bef=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 3rd day before the incident
mask = (RestaurantLV['date'] > '2017-09-26 00:00:00')&(RestaurantLV['date'] <= '2017-09-27 00:00:00')
ondays3bef=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
# 1 days before the incident
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-01 00:00:00')
days1bef=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 1st day before the incident
mask = (RestaurantLV['date'] > '2017-09-30 00:00:00')&(RestaurantLV['date'] <= '2017-10-01 00:00:00')
ondays1bef=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()

#aggregating data cross sectional wise
# on the day of incident  
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-02 00:00:00')
days0=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#
#mask = (RestaurantLV['date'] > '2017-10-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-02 00:00:00')
#onday0=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()

#1 day after the incident
mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-03 00:00:00')
days1aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 1st day after the incident
mask = (RestaurantLV['date'] > '2017-10-02 00:00:00')&(RestaurantLV['date'] <= '2017-10-03 00:00:00')
onday1aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#3 days after the incident

mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-04 00:00:00')
days3aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 3rd day after the incident

mask = (RestaurantLV['date'] > '2017-10-03 00:00:00')&(RestaurantLV['date'] <= '2017-10-04 00:00:00')
onday3aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#5 days after the incident

mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-06 00:00:00')
days5aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 5th day after the incident

mask = (RestaurantLV['date'] > '2017-10-05 00:00:00')&(RestaurantLV['date'] <= '2017-10-06 00:00:00')
onday5aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#7 days after the incident

mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-08 00:00:00')
days7aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 7th day after the incident

mask = (RestaurantLV['date'] > '2017-10-07 00:00:00')&(RestaurantLV['date'] <= '2017-10-08 00:00:00')
onday7aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#14 days after the incident

mask = (RestaurantLV['date'] > '2017-01-01 00:00:00')&(RestaurantLV['date'] <= '2017-10-15 00:00:00')
days14aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()
#on the 14th day after the incident

mask = (RestaurantLV['date'] > '2017-10-14 00:00:00')&(RestaurantLV['date'] <= '2017-10-15 00:00:00')
onday14aft=RestaurantLV.loc[mask].groupby(['name','postal_code','latitude','longitude','predictions']).size().unstack()

#renaming the columns 
ondaybef14.columns=['neg_14_bef','pos_14_bef']
ondaybef7.columns=['neg_7_bef','pos_7_bef']
onday5bef.columns=['neg_5_bef','pos_5_bef']
ondays3bef.columns=['neg_3_bef','pos_3_bef']
ondays1bef.columns=['neg_1_bef','pos_1_bef']
onday14aft.columns=['neg_14_aft','pos_14_aft']
onday7aft.columns=['neg_7_aft','pos_7_aft']
onday5aft.columns=['neg_5_aft','pos_5_aft']
onday3aft.columns=['neg_3_aft','pos_3_aft']
onday1aft.columns=['neg_1_aft','pos_1_aft']
onday0.columns=['neg_0','pos_0']

daysbef14.columns=['neg_14_bef','pos_14_bef']
daysbef7.columns=['neg_7_bef','pos_7_bef']
days5bef.columns=['neg_5_bef','pos_5_bef']
days3bef.columns=['neg_3_bef','pos_3_bef']
days1bef.columns=['neg_1_bef','pos_1_bef']
days14aft.columns=['neg_14_aft','pos_14_aft']
days7aft.columns=['neg_7_aft','pos_7_aft']
days5aft.columns=['neg_5_aft','pos_5_aft']
days3aft.columns=['neg_3_aft','pos_3_aft']
days1aft.columns=['neg_1_aft','pos_1_aft']
days0.columns=['neg_0','pos_0']

#reseting indexes to merge the aggregrated data
ondaybef14.reset_index(inplace=True)
ondaybef7.reset_index(inplace=True)
onday5bef.reset_index(inplace=True)
ondays3bef.reset_index(inplace=True)
ondays1bef.reset_index(inplace=True)
onday14aft.reset_index(inplace=True)
onday7aft.reset_index(inplace=True)
onday5aft.reset_index(inplace=True)
onday3aft.reset_index(inplace=True)
onday1aft.reset_index(inplace=True)
onday0.reset_index(inplace=True)
days5aft.reset_index(inplace=True)
days3aft.reset_index(inplace=True)
days1aft.reset_index(inplace=True)
days7aft.reset_index(inplace=True)
days14aft.reset_index(inplace=True)
days1bef.reset_index(inplace=True)
days5bef.reset_index(inplace=True)
days3bef.reset_index(inplace=True)
daysbef14.reset_index(inplace=True)
daysbef7.reset_index(inplace=True)
days0.reset_index(inplace=True)

# preparing Restaurant dataframe for merging aggregated data
Restaurantname=RestaurantLV.groupby(['name','postal_code','latitude','longitude']).size().reset_index()
Restaurantname=Restaurantname.drop(0,axis=1)

df=pd.melt(Restaurantname,id_vars=["name", "postal_code"])

#merging aggregated data with restaurant data
Restaurantname=Restaurantname.merge(daysbef14,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(daysbef7,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days5bef,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days3bef,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days1bef,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days0,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days1aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days3aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days5aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days7aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(days14aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')

Restaurantname=Restaurantname.merge(ondaybef14,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(ondaybef7,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday5bef,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(ondays3bef,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(ondays1bef,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday0,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday1aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday3aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday5aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday7aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')
Restaurantname=Restaurantname.merge(onday14aft,left_on=['name','postal_code','latitude','longitude'],right_on=['name','postal_code','latitude','longitude'],how='left')

Restaurantname=Restaurantname.fillna(0)

#total comments from negative and positive comments 
Restaurantname['14daysbef']=Restaurantname['neg_14_bef']+Restaurantname['pos_14_bef']
Restaurantname['7daysbef']=Restaurantname['neg_7_bef']+Restaurantname['pos_7_bef']
Restaurantname['5daysbef']=Restaurantname['neg_5_bef']+Restaurantname['pos_5_bef']
Restaurantname['3daysbef']=Restaurantname['neg_3_bef']+Restaurantname['pos_3_bef']
Restaurantname['1daysbef']=Restaurantname['neg_1_bef']+Restaurantname['pos_1_bef']
Restaurantname['onthatday']=Restaurantname['neg_0']+Restaurantname['pos_0']
Restaurantname['1daysaft']=Restaurantname['neg_1_aft']+Restaurantname['pos_1_aft']
Restaurantname['3daysaft']=Restaurantname['neg_3_aft']+Restaurantname['pos_3_aft']
Restaurantname['5daysaft']=Restaurantname['neg_5_aft']+Restaurantname['pos_5_aft']
Restaurantname['7daysaft']=Restaurantname['neg_7_aft']+Restaurantname['pos_7_aft']
Restaurantname['14daysaft']=Restaurantname['neg_14_aft']+Restaurantname['pos_14_aft']
Restaurantname['14daysbef_y']=Restaurantname['neg_14_bef_y']+Restaurantname['pos_14_bef_y']
Restaurantname['7daysbef_y']=Restaurantname['neg_7_bef_y']+Restaurantname['pos_7_bef_y']
Restaurantname['5daysbef_y']=Restaurantname['neg_5_bef_y']+Restaurantname['pos_5_bef_y']
Restaurantname['3daysbef_y']=Restaurantname['neg_3_bef_y']+Restaurantname['pos_3_bef_y']
Restaurantname['1daysbef_y']=Restaurantname['neg_1_bef_y']+Restaurantname['pos_1_bef_y']
Restaurantname['onthatday_y']=Restaurantname['neg_0_y']+Restaurantname['pos_0_y']
Restaurantname['1daysaft_y']=Restaurantname['neg_1_aft_y']+Restaurantname['pos_1_aft_y']
Restaurantname['3daysaft_y']=Restaurantname['neg_3_aft_y']+Restaurantname['pos_3_aft_y']
Restaurantname['5daysaft_y']=Restaurantname['neg_5_aft_y']+Restaurantname['pos_5_aft_y']
Restaurantname['7daysaft_y']=Restaurantname['neg_7_aft_y']+Restaurantname['pos_7_aft_y']
Restaurantname['14daysaft_y']=Restaurantname['neg_14_aft_y']+Restaurantname['pos_14_aft_y']

#converting to long format total comments 
complete=Restaurantname[['name', 'postal_code','latitude','longitude','14daysbef', '7daysbef',
       '5daysbef', '3daysbef', '1daysbef', 'onthatday', '1daysaft', '3daysaft',
       '5daysaft', '7daysaft', '14daysaft']]
complete2=complete.melt(id_vars=['name','postal_code','latitude','longitude'])
complete2=complete2.sort_values(['name','postal_code','latitude','longitude'])
complete2.columns=['name', 'postal_code','latitude','longitude', 'Day', 'accum_tot_comment']
complete2.reset_index(inplace=True)
complete2=complete2.drop('index',axis=1)

#converting to long format on that day total comments
oncomplete=Restaurantname[['name','postal_code','latitude','longitude','14daysbef_y', '7daysbef_y',
       '5daysbef_y', '3daysbef_y', '1daysbef_y', 'onthatday_y', '1daysaft_y',
       '3daysaft_y', '5daysaft_y', '7daysaft_y', '14daysaft_y']]
oncomplete.columns=['name', 'postal_code','latitude','longitude','14daysbef', '7daysbef',
       '5daysbef', '3daysbef', '1daysbef', 'onthatday', '1daysaft', '3daysaft',
       '5daysaft', '7daysaft', '14daysaft']
oncomplete2=oncomplete.melt(id_vars=['name','postal_code','latitude','longitude'])
oncomplete2=oncomplete2.sort_values(['name','postal_code','latitude','longitude'])
oncomplete2.columns=['name', 'postal_code','latitude','longitude', 'Day', 'comments_of_day']
oncomplete2.reset_index(inplace=True)
oncomplete2=oncomplete2.drop('index',axis=1)

#converting to long format negative comments 
neg=Restaurantname[['name', 'postal_code','latitude','longitude','neg_14_bef', 'neg_7_bef', 'neg_5_bef', 'neg_3_bef',
       'neg_1_bef', 'neg_0', 'neg_1_aft','neg_3_aft', 'neg_5_aft', 'neg_7_aft', 'neg_14_aft',]]
neg.columns=['name','postal_code','latitude','longitude','14daysbef', '7daysbef',
       '5daysbef', '3daysbef', '1daysbef', 'onthatday', '1daysaft', '3daysaft',
       '5daysaft', '7daysaft', '14daysaft']
neg2=neg.melt(id_vars=['name','postal_code','latitude','longitude'])
neg2=neg2.sort_values(['name','postal_code','latitude','longitude'])
neg2.columns=['name', 'postal_code','latitude','longitude', 'Day', 'Total_accum_negative']
neg2.reset_index(inplace=True)
neg2=neg2.drop('index',axis=1)

#converting to long format on that day negative comments 
onneg=Restaurantname[['name', 'postal_code','latitude','longitude','neg_14_bef_y', 'neg_7_bef_y', 'neg_5_bef_y', 'neg_3_bef_y',
       'neg_1_bef_y', 'neg_0_y', 'neg_1_aft_y','neg_3_aft_y', 'neg_5_aft_y', 'neg_7_aft_y', 'neg_14_aft_y']]
onneg.columns=['name','postal_code','latitude','longitude','14daysbef', '7daysbef',
       '5daysbef', '3daysbef', '1daysbef', 'onthatday', '1daysaft', '3daysaft',
       '5daysaft', '7daysaft', '14daysaft']
onneg2=onneg.melt(id_vars=['name','postal_code','latitude','longitude'])
onneg2=onneg2.sort_values(['name','postal_code','latitude','longitude'])
onneg2.columns=['name', 'postal_code','latitude','longitude', 'Day', 'neg_comment']
onneg2.reset_index(inplace=True)
onneg2=onneg2.drop('index',axis=1)

#converting to long format postive comments
pos=Restaurantname[['name', 'postal_code','latitude','longitude','pos_14_bef',
       'pos_7_bef', 'pos_5_bef', 'pos_3_bef', 'pos_1_bef', 'pos_0', 'pos_1_aft', 'pos_3_aft', 'pos_5_aft',
       'pos_7_aft', 'pos_14_aft']]
pos.columns=['name','postal_code','latitude','longitude','14daysbef', '7daysbef',
       '5daysbef', '3daysbef', '1daysbef', 'onthatday', '1daysaft', '3daysaft',
       '5daysaft', '7daysaft', '14daysaft']
pos2=pos.melt(id_vars=['name','postal_code','latitude','longitude'])
pos2=pos2.sort_values(['name','postal_code','latitude','longitude'])
pos2.columns=['name', 'postal_code','latitude','longitude', 'Day', 'Total_accum_positive']
pos2.reset_index(inplace=True)
pos2=pos2.drop('index',axis=1)

#converting to long format on that day positive comments
onpos=Restaurantname[['name', 'postal_code','latitude','longitude','pos_14_bef_y',
       'pos_7_bef_y', 'pos_5_bef_y', 'pos_3_bef_y', 'pos_1_bef_y', 'pos_0_y', 'pos_1_aft_y', 'pos_3_aft_y', 'pos_5_aft_y',
       'pos_7_aft_y', 'pos_14_aft_y']]
onpos.columns=['name','postal_code','latitude','longitude','14daysbef', '7daysbef',
       '5daysbef', '3daysbef', '1daysbef', 'onthatday', '1daysaft', '3daysaft',
       '5daysaft', '7daysaft', '14daysaft']
onpos2=onpos.melt(id_vars=['name','postal_code','latitude','longitude'])
onpos2=onpos2.sort_values(['name','postal_code','latitude','longitude'])
onpos2.columns=['name', 'postal_code','latitude','longitude', 'Day', 'pos_comment']
onpos2.reset_index(inplace=True)
onpos2=onpos2.drop('index',axis=1)

#merging all the long datasets
oncomplete2=oncomplete2.merge(onpos2,how='left',on=['name','postal_code','latitude','longitude','Day'])
oncomplete2=oncomplete2.merge(onneg2,how='left',on=['name','postal_code','latitude','longitude','Day'])

complete2=complete2.merge(pos2,how='left',on=['name','postal_code','latitude','longitude','Day'])
complete2=complete2.merge(neg2,how='left',on=['name','postal_code','latitude','longitude','Day'])

complete2=complete2.merge(oncomplete2,how='left',on=['name','postal_code','latitude','longitude','Day'])

#complete2.isna().sum()

# creating a new variable nearby
complete2['nearby_89109']= complete2['postal_code']==89109
complete2['nearby_89119']=complete2['postal_code']==89119

#merging restaurant type 
superman=restomerge[['name','postal_code','latitude','longitude','stars', 'Chinese',
       'Italian', 'Thai', 'Mexican', 'Japanese', 'Caribbean', 'Mediterranean',
       'LatinAmerican', 'Saturday', 'Sunday']]
superwoman=superman.drop_duplicates()

#type conversions
complete2['name']=complete2['name'].astype('str')
complete2['postal_code']=complete2['postal_code'].astype('int')
complete2['latitude']=complete2['latitude'].astype('float')
complete2['longitude']=complete2['longitude'].astype('float')


superman['name']=superman['name'].astype('str')
superman['postal_code']=superman['postal_code'].astype('int')
superman['latitude']=superman['latitude'].astype('float')
superman['longitude']=superman['longitude'].astype('float')

#preparing this dataframe to merge with complete
superman.reset_index(inplace=True)
superman=superman.drop('index',axis=1)
superman.drop_duplicates(inplace=True)

#sanity check: each restaurant has 11 rows
complete2['id'] = pd.factorize(complete2.name+complete2.postal_code.astype('str')+complete2.latitude.astype('str')+complete2.longitude.astype('str'))[0]
complete2['id'].value_counts()

#merging complete and superman datasets 
vital=complete2.merge(superman,how='left',on=['name','postal_code','latitude','longitude'])

#vital.isna().sum()

#Extracting Stars data from Business Dataset
business = pd.read_json('/content/gdrive/My Drive/inference/business.json',lines=True)
LVbusiness=business[business['city']=='Las Vegas']
LVbusiness = LVbusiness[LVbusiness['categories'].notnull()]

#preparing restaurant data to merge with business dataset
Restaurantname=Restaurantname.fillna(0)
Restaurantname['postal_code']=Restaurantname['postal_code'].astype('int')
Restaurantname['postal_code']=Restaurantname['postal_code'].astype('str')

#merging starts data 
LVRestaurants=Restaurantname.merge(LVbusiness, on=['name','postal_code'],how='left')

#removing redundant variables
LVRestaurants=LVRestaurants.drop(['address','business_id','city','state'],axis=1)

#treatement and control groups 
treatment=(vital['latitude']>36.0724) & (vital['latitude']< 36.1151) & (vital['longitude']> -115.2068) & (vital['longitude']< -115.1525) 
vital['treatment']=treatment.astype(int)

control2=(vital['latitude']>36.1556) & (vital['latitude']<36.1983 ) & (vital['longitude']> -115.1683) & (vital['longitude']< -115.1140)
vital['control2']=control2.astype(int)

vital_exp=vital[(vital["control2"]==1) | (vital["treatment"]==1)]

#dummy date variable for diff and diff model 
vital_exp["diff_date"]=(vital_exp["Day"]=="1daysaft")|(vital_exp["Day"]=="3daysaft")|(vital_exp["Day"]=="7daysaft")|(vital_exp["Day"]=="5daysaft")|(vital_exp["Day"]=="14daysaft")
vital_exp["diff_date"]=vital_exp["diff_date"].astype(int)
vital_exp=vital_exp.reset_index()
vital_exp=vital_exp.drop(["index","Unnamed: 0"],axis=1)

#saving files
vital_exp.to_csv('/content/gdrive/My Drive/inference/vital_experiment2.csv')
LVRestaurants.to_csv('/content/gdrive/My Drive/inference/LVRestaurantsacc.csv')
vital.to_csv('/content/gdrive/My Drive/inference/Restaurantdif3.csv')
complete2.to_csv('/content/gdrive/My Drive/inference/complete2.csv')
superman.to_csv('/content/gdrive/My Drive/inference/superman.csv')